{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b3960ff-6c0f-462a-bf4f-0eb70ac909b6",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50496cc0-f2ad-42ca-b90c-abef1f34922a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:29:51.181913Z",
     "iopub.status.busy": "2025-02-21T11:29:51.181335Z",
     "iopub.status.idle": "2025-02-21T11:29:51.185394Z",
     "shell.execute_reply": "2025-02-21T11:29:51.184859Z",
     "shell.execute_reply.started": "2025-02-21T11:29:51.181884Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import load_model\n",
    "from transformers import AutoTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10516ae1-5479-420e-b3b7-bc20709df77e",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdd5c7a3-00fe-4e6f-b4ed-8dde4f445978",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:29:51.187165Z",
     "iopub.status.busy": "2025-02-21T11:29:51.186534Z",
     "iopub.status.idle": "2025-02-21T11:29:52.269322Z",
     "shell.execute_reply": "2025-02-21T11:29:52.268893Z",
     "shell.execute_reply.started": "2025-02-21T11:29:51.187138Z"
    }
   },
   "outputs": [],
   "source": [
    "data_path = \"cleaned_mbti_data.csv\" \n",
    "data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a8ecdd-5f59-4783-977f-54d8173c11fb",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f238db37-371e-4391-a8cd-41acb676de26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:29:52.270638Z",
     "iopub.status.busy": "2025-02-21T11:29:52.269984Z",
     "iopub.status.idle": "2025-02-21T11:29:57.481635Z",
     "shell.execute_reply": "2025-02-21T11:29:57.481203Z",
     "shell.execute_reply.started": "2025-02-21T11:29:52.270619Z"
    }
   },
   "outputs": [],
   "source": [
    "vocab_size = 10000\n",
    "maxlen = 1500\n",
    "trunc_type = \"post\"\n",
    "pad_type = \"post\"\n",
    "oov_tok = \"<OOV>\"\n",
    "\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=vocab_size, oov_token=oov_tok)\n",
    "tokenizer.fit_on_texts(data.cleaned_text.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382cc032-ac8f-48df-850e-c05ef6124a6e",
   "metadata": {},
   "source": [
    "## Convert text to sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80febb0a-83e6-4e0c-90af-a544a6849803",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:29:57.482590Z",
     "iopub.status.busy": "2025-02-21T11:29:57.482281Z",
     "iopub.status.idle": "2025-02-21T11:30:00.738515Z",
     "shell.execute_reply": "2025-02-21T11:30:00.738071Z",
     "shell.execute_reply.started": "2025-02-21T11:29:57.482572Z"
    }
   },
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(data.cleaned_text.values)\n",
    "padded_sequences = pad_sequences(sequences, maxlen=maxlen, truncating=trunc_type, padding=pad_type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ec517c-d0ac-4b89-b52c-5efaff65a1d1",
   "metadata": {},
   "source": [
    "## Convert labels to categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7473716-14ed-4af1-a312-56f8b23effed",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:30:00.740674Z",
     "iopub.status.busy": "2025-02-21T11:30:00.739895Z",
     "iopub.status.idle": "2025-02-21T11:30:00.758626Z",
     "shell.execute_reply": "2025-02-21T11:30:00.758165Z",
     "shell.execute_reply.started": "2025-02-21T11:30:00.740645Z"
    }
   },
   "outputs": [],
   "source": [
    "types = np.unique(data[\"type\"].values)\n",
    "def get_type_index(string):\n",
    "    return list(types).index(string)\n",
    "\n",
    "data[\"type_index\"] = data[\"type\"].apply(get_type_index)\n",
    "labels = tf.keras.utils.to_categorical(data.type_index.values, num_classes=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b858033-439f-4537-bb1e-e700e498f242",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:30:00.760228Z",
     "iopub.status.busy": "2025-02-21T11:30:00.759314Z",
     "iopub.status.idle": "2025-02-21T11:30:01.557705Z",
     "shell.execute_reply": "2025-02-21T11:30:01.557180Z",
     "shell.execute_reply.started": "2025-02-21T11:30:00.760202Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, test_X, _, test_y = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1d092a-5c80-43c4-9614-8680d77e576f",
   "metadata": {},
   "source": [
    "## Load trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4755d272-0083-4ea4-bf80-e02fffd1db25",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:30:01.559278Z",
     "iopub.status.busy": "2025-02-21T11:30:01.558435Z",
     "iopub.status.idle": "2025-02-21T11:30:21.334724Z",
     "shell.execute_reply": "2025-02-21T11:30:21.334235Z",
     "shell.execute_reply.started": "2025-02-21T11:30:01.559278Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading trained models...\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 11:30:01.654268: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:01.768777: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:01.768964: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:01.770400: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:01.770583: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:01.770669: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:02.891278: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:02.891445: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:02.891549: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-02-21 11:30:02.891631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 46689 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:00:05.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading trained models...\")\n",
    "lstm_model = load_model(\"models/lstm_model.h5\")\n",
    "bilstm_model = load_model(\"models/bilstm_model.h5\")\n",
    "\n",
    "from transformers import TFBertModel\n",
    "from tensorflow.keras.utils import custom_object_scope\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "with custom_object_scope({'TFBertModel': TFBertModel}):\n",
    "    bert_model = load_model(\"models/bert_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5224c0-5dcd-4dde-ba21-26497e96b43c",
   "metadata": {},
   "source": [
    "## Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "50dbbf10-d3a1-4909-87a4-49fded090471",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:30:21.337098Z",
     "iopub.status.busy": "2025-02-21T11:30:21.336437Z",
     "iopub.status.idle": "2025-02-21T11:30:45.927461Z",
     "shell.execute_reply": "2025-02-21T11:30:45.926998Z",
     "shell.execute_reply.started": "2025-02-21T11:30:21.337077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating models...\n",
      "\n",
      "55/55 [==============================] - 20s 326ms/step - loss: 2.1984 - accuracy: 0.2542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-21 11:30:42.548099: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8902\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 5s 56ms/step - loss: 1.7140 - accuracy: 0.5303\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluating models...\\n\")\n",
    "lstm_loss, lstm_acc = lstm_model.evaluate(test_X, test_y, verbose=1)\n",
    "bilstm_loss, bilstm_acc = bilstm_model.evaluate(test_X, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e1085286-6b2e-4245-9148-1c409421cc20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:30:45.928467Z",
     "iopub.status.busy": "2025-02-21T11:30:45.928296Z",
     "iopub.status.idle": "2025-02-21T11:31:15.359475Z",
     "shell.execute_reply": "2025-02-21T11:31:15.358900Z",
     "shell.execute_reply.started": "2025-02-21T11:30:45.928451Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35576781408744779ab86a7c967ddcdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89835d6e60ec4c5988260e9a757e2c05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afe3b574678c4712a6e4c4c3079d70f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a13a8e21d32441fbea6e7c52da68fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:2614: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "test_input_ids = np.array([bert_tokenizer.encode(str(i), max_length=maxlen, pad_to_max_length=True) for i in data.cleaned_text.values])\n",
    "_, test_input_ids, _, test_y = train_test_split(test_input_ids, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47b4cd0b-48ac-4dcb-8979-87be86aaba9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:31:15.360713Z",
     "iopub.status.busy": "2025-02-21T11:31:15.360484Z",
     "iopub.status.idle": "2025-02-21T11:32:35.649110Z",
     "shell.execute_reply": "2025-02-21T11:32:35.648446Z",
     "shell.execute_reply.started": "2025-02-21T11:31:15.360667Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 80s 1s/step - loss: 0.6503 - accuracy: 0.8582\n"
     ]
    }
   ],
   "source": [
    "bert_loss, bert_acc = bert_model.evaluate(test_input_ids, test_y, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15b3b7e-0fa5-45a5-b759-25a659451b8a",
   "metadata": {},
   "source": [
    "## Model comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "361575a0-2271-42ed-b32b-6fbb479b65ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-21T11:32:35.650751Z",
     "iopub.status.busy": "2025-02-21T11:32:35.650177Z",
     "iopub.status.idle": "2025-02-21T11:32:35.672651Z",
     "shell.execute_reply": "2025-02-21T11:32:35.671959Z",
     "shell.execute_reply.started": "2025-02-21T11:32:35.650751Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance Comparison:\n",
      "                 Model  Accuracy      Loss\n",
      "0                 LSTM  0.254179  2.198353\n",
      "1  Bi-Directional LSTM  0.530259  1.713998\n",
      "2                 BERT  0.858213  0.650264\n",
      "Evaluation complete! Results saved in 'model_comparison_results.csv'.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "results_df = pd.DataFrame({\n",
    "    \"Model\": [\"LSTM\", \"Bi-Directional LSTM\", \"BERT\"],\n",
    "    \"Accuracy\": [lstm_acc, bilstm_acc, bert_acc],\n",
    "    \"Loss\": [lstm_loss, bilstm_loss, bert_loss]\n",
    "})\n",
    "\n",
    "print(\"Model Performance Comparison:\")\n",
    "print(results_df)\n",
    "\n",
    "results_df.to_csv(\"model_comparison_results.csv\", index=False)\n",
    "\n",
    "print(\"Evaluation complete! Results saved in 'model_comparison_results.csv'.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
